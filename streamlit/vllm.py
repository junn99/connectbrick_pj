import streamlit as st
import requests
import json
from transformers import AutoTokenizer

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="AI ì±—ë´‡", page_icon="ğŸ’")
st.title("AI ì±—ë´‡")

# Initialize tokenizer
@st.cache_resource
def load_tokenizer():
    return AutoTokenizer.from_pretrained("beomi/Llama-3-Open-Ko-8B")

tokenizer = load_tokenizer()

# vLLM ì„œë²„ ì„¤ì •
vllm_host = "http://localhost:8000"
headers = {"Content-Type": "application/json"}

# Initialize session state for chat history
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "system", "content": "ë‹¹ì‹ ì€ ì§ˆë¬¸ì— ì¹œê·¼í•˜ê²Œ ë‹µë³€í•˜ëŠ” ì• ì¸ì…ë‹ˆë‹¤."}
    ]

def clean_response(response):
    """ì²« ë²ˆì§¸ ì˜ë¯¸ ìˆëŠ” ì‘ë‹µë§Œ ì¶”ì¶œ"""
    if not response:
        return ""
        
    # íŠ¹ì • íƒœê·¸ë‚˜ í…ìŠ¤íŠ¸ ì´ì „ì˜ ë‚´ìš© ì œê±°
    for tag in ["<|begin_of_text|>", "<|start_header_id|>", "<|end_header_id|>", "<|eot_id|>"]:
        if tag in response:
            response = response.split(tag)[-1]
            
    # ì²« ë²ˆì§¸ ë¬¸ì¥ ì¶”ì¶œ (ë§ˆì¹¨í‘œ, ë¬¼ìŒí‘œ, ëŠë‚Œí‘œ ê¸°ì¤€)
    sentences = response.replace('?', '.').replace('!', '.').split('.')
    for sentence in sentences:
        clean_text = sentence.strip()
        if clean_text:  # ì˜ë¯¸ ìˆëŠ” ì²« ë²ˆì§¸ ë¬¸ì¥ ë°˜í™˜
            return clean_text
            
    return response.strip()

def generate_response(messages):
    try:
        # í† í¬ë‚˜ì´ì €ë¡œ ì±„íŒ… í…œí”Œë¦¿ ì ìš©
        prompt = tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True
        )
        
        # vLLM API í˜¸ì¶œ
        response = requests.post(
            f"{vllm_host}/generate",
            headers=headers,
            json={
                "prompt": prompt,
                "temperature": temperature,
                "max_tokens": max_tokens,
                "top_p": 0.9,
                "stop": ["<|end_of_text|>"]
            }
        )
        
        if response.status_code == 200:
            response_text = response.json()["text"][0]
            return clean_response(response_text)
            
    except Exception as e:
        st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

# Sidebar for parameters
with st.sidebar:
    st.header("ìƒì„± íŒŒë¼ë¯¸í„°")
    max_tokens = st.slider("ìµœëŒ€ í† í° ìˆ˜", 1, 1024, 512)
    temperature = st.slider("Temperature", 0.0, 1.0, 0.7)

# Chat container for better scrolling
chat_container = st.container()

# Display chat history in the container
with chat_container:
    for message in st.session_state.messages[1:]:  # Skip system message
        role = "ğŸ§‘" if message["role"] == "user" else "ğŸ’"
        st.markdown(f"**{role}:** {message['content']}")

# Chat input
with st.form(key="chat_form"):
    user_input = st.text_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", key="user_message")
    submit = st.form_submit_button("ì „ì†¡")
    
    if submit and user_input:
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": user_input})
        
        # ì‘ë‹µ ìƒì„±
        response = generate_response(st.session_state.messages)
        
        if response:
            # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì¶”ê°€
            st.session_state.messages.append({"role": "assistant", "content": response})
            
        st.rerun()

# Clear chat button    
if st.sidebar.button("ëŒ€í™”ë‚´ìš© ì§€ìš°ê¸°"):
    st.session_state.messages = [
        {"role": "system", "content": "ë‹¹ì‹ ì€ ì§ˆë¬¸ì— ì¹œê·¼í•˜ê²Œ ë‹µë³€í•˜ëŠ” ì• ì¸ì…ë‹ˆë‹¤."}
    ]
    st.rerun()